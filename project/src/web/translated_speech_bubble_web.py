import sys
import asyncio
import logging
import time
import cv2
import boto3
import numpy as np
import pyaudio
import socket
from amazon_transcribe.client import TranscribeStreamingClient
from amazon_transcribe.handlers import TranscriptResultStreamHandler
from amazon_transcribe.model import TranscriptEvent
import tkinter as tk
import threading
from flask import Flask, render_template
from flask_socketio import SocketIO, emit

# ===============================
#   å®šæ•°ãƒ»è¨­å®šã®å®šç¾©
# ===============================
SAMPLE_RATE = 16000
CHUNK_SIZE = 1024
MEDIA_ENCODING = "pcm"
COMPREHEND_LANGUAGE_CODE = "ja"
TRANSCRIPT_LANGUAGE_CODE = "ja-JP"  # åˆæœŸå€¤
TARGET_LANGUAGE_CODE = "en-US"    # åˆæœŸå€¤
REGION = "ap-northeast-1"
SILENCE_THRESHOLD = 1.0  # 1ç§’ç„¡éŸ³ã§éè¡¨ç¤º

# ãƒ­ã‚¬ãƒ¼ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Flask ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
app = Flask(__name__)
app.config['SECRET_KEY'] = 'comic-effect-secret'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ç®¡ç†
class SystemState:
    def __init__(self):
        self.last_transcript_time = time.time()
        self.current_text = ""
        self.current_y_position = 0
        self.is_visible = False
        self.connected_clients = 0

system_state = SystemState()


# ===============================
#   è¨€èªé¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
# ===============================
def get_language_settings():
    lang_root = tk.Tk()
    lang_root.withdraw()
    dialog = tk.Toplevel(lang_root)
    dialog.title("è¨€èªè¨­å®š")
    tk.Label(dialog, text="ç¿»è¨³å…ƒè¨€èª:").grid(row=0, column=0, padx=10, pady=10)
    tk.Label(dialog, text="ç¿»è¨³å…ˆè¨€èª:").grid(row=1, column=0, padx=10, pady=10)

    languages = ["ja-JP", "en-US", "fr-FR", "de-DE", "es-ES"]
    source_var = tk.StringVar(value=languages[0])
    target_var = tk.StringVar(value=languages[1])
    tk.OptionMenu(dialog, source_var, *languages).grid(row=0, column=1, padx=10, pady=10)
    tk.OptionMenu(dialog, target_var, *languages).grid(row=1, column=1, padx=10, pady=10)

    result = {}
    def on_ok():
        result['source'] = source_var.get()
        result['target'] = target_var.get()
        dialog.destroy()
    tk.Button(dialog, text="OK", command=on_ok).grid(row=2, column=0, columnspan=2, pady=10)
    dialog.grab_set()
    lang_root.wait_window(dialog)
    lang_root.destroy()
    return result['source'], result['target']


# ===============================
#   Flask ãƒ«ãƒ¼ãƒˆ
# ===============================
@app.route('/')
def index():
    return render_template('speech_bubble.html')


# ===============================
#   SocketIO ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
# ===============================
@socketio.on('connect')
def handle_connect():
    system_state.connected_clients += 1
    logger.info(f'Client connected. Total clients: {system_state.connected_clients}')
    # ç¾åœ¨ã®çŠ¶æ…‹ã‚’æ–°ã—ã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡
    if system_state.is_visible:
        emit('update_text', {'text': system_state.current_text})
        emit('update_position', {'y': system_state.current_y_position})
        emit('show_bubble')
    else:
        emit('hide_bubble')


@socketio.on('disconnect')
def handle_disconnect():
    system_state.connected_clients -= 1
    logger.info(f'Client disconnected. Total clients: {system_state.connected_clients}')


@socketio.on('client_ready')
def handle_client_ready(data):
    logger.info(f'Client ready with screen: {data.get("screen_width")}x{data.get("screen_height")}')


# ===============================
#   éŸ³å£°èªè­˜ã‚¹ãƒ¬ãƒƒãƒ‰
# ===============================
class AudioTranscriptionThread(threading.Thread):
    """éŸ³å£°èªè­˜ã‚¹ãƒ¬ãƒƒãƒ‰"""
    def __init__(self):
        super().__init__()
        self.loop = None
        self.daemon = True

    def run(self):
        self.loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.loop)
        self.loop.run_until_complete(self.transcribe_stream())

    async def transcribe_stream(self):
        try:
            client = TranscribeStreamingClient(region=REGION)
            stream = await client.start_stream_transcription(
                language_code=TRANSCRIPT_LANGUAGE_CODE,
                media_sample_rate_hz=SAMPLE_RATE,
                media_encoding=MEDIA_ENCODING,
            )
            logger.info("Started transcription stream.")

            p = pyaudio.PyAudio()
            audio_stream = p.open(format=pyaudio.paInt16,
                                  channels=1,
                                  rate=SAMPLE_RATE,
                                  input=True,
                                  frames_per_buffer=CHUNK_SIZE)
            logger.info("Audio stream opened.")

            async def write_chunks():
                try:
                    while True:
                        try:
                            data = await asyncio.to_thread(
                                audio_stream.read, CHUNK_SIZE, exception_on_overflow=False
                            )
                        except IOError as e:
                            logger.error(f"Audio read error: {e}")
                            continue
                        audio_np = np.frombuffer(data, dtype=np.int16)
                        if np.abs(audio_np).mean() > 100:
                            logger.info("Audio detected!")
                        await stream.input_stream.send_audio_event(audio_chunk=data)
                except asyncio.CancelledError:
                    pass
                finally:
                    await stream.input_stream.end_stream()

            handler = MyEventHandler(stream.output_stream)
            await asyncio.gather(write_chunks(), handler.handle_events())

        except Exception as e:
            logger.error(f"Error in transcribe_stream: {e}")
        finally:
            audio_stream.stop_stream()
            audio_stream.close()
            p.terminate()


# ===============================
#   éŸ³å£°èªè­˜ -> ç¿»è¨³ -> WebSocketé…ä¿¡
# ===============================
class MyEventHandler(TranscriptResultStreamHandler):
    def __init__(self, output_stream):
        super().__init__(output_stream)

    def translate_text(self, text):
        translate = boto3.client("translate", region_name=REGION, use_ssl=True)
        result = translate.translate_text(
            Text=text,
            SourceLanguageCode=TRANSCRIPT_LANGUAGE_CODE,
            TargetLanguageCode=TARGET_LANGUAGE_CODE
        )
        return result.get("TranslatedText", text)

    async def handle_transcript_event(self, transcript_event: TranscriptEvent):
        results = transcript_event.transcript.results
        for result in results:
            for alt in result.alternatives:
                transcript = alt.transcript
                logger.info(f"Transcription: {transcript}")
                # ç¿»è¨³ã‚’éåŒæœŸã§å®Ÿè¡Œ
                translated = await asyncio.to_thread(self.translate_text, transcript)
                logger.info(f"Translated: {translated}")

                # çŠ¶æ…‹ã‚’æ›´æ–°
                system_state.last_transcript_time = time.time()
                system_state.current_text = translated
                system_state.is_visible = True

                # WebSocketã§å…¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡
                socketio.emit('update_text', {'text': translated})
                socketio.emit('show_bubble')


# ===============================
#   é¡”æ¤œå‡ºã‚¹ãƒ¬ãƒƒãƒ‰
# ===============================
class FaceDetectionThread(threading.Thread):
    """
    ã‚«ãƒ¡ãƒ©æ˜ åƒã‹ã‚‰é¡”æ¤œå‡ºã‚’è¡Œã„ã€æ¤œå‡ºã•ã‚ŒãŸé¡”ã®ä¸Šç«¯ã«åŸºã¥ã„ã¦
    å¹ãå‡ºã—ã®ä½ç½®ã‚’æ›´æ–°ã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã™ã€‚
    """
    def __init__(self, offset=600):
        super().__init__()
        self.offset = offset
        self.running = True
        self.daemon = True
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

    def run(self):
        cap = cv2.VideoCapture(0)
        # iPhoneã®å…¸å‹çš„ãªè§£åƒåº¦ã«åˆã‚ã›ã‚‹ï¼ˆä¾‹: iPhone 14 Pro = 1179x2556ï¼‰
        # ãŸã ã—ã€ã‚«ãƒ¡ãƒ©ã¯é€šå¸¸ã®è§£åƒåº¦ã§å–å¾—
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)

        while self.running:
            ret, frame = cap.read()
            if not ret:
                continue

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)

            if len(faces) > 0:
                (x, y, w, h) = faces[0]
                face_top = y
                # ä½ç½®èª¿æ•´
                new_y = face_top - self.offset
                if new_y < 0:
                    new_y = 0

                # çŠ¶æ…‹ã‚’æ›´æ–°
                system_state.current_y_position = new_y

                # WebSocketã§ä½ç½®æƒ…å ±ã‚’é€ä¿¡
                socketio.emit('update_position', {'y': new_y})
                logger.info(f"Face detected at y={face_top}, bubble position={new_y}")

            time.sleep(0.1)

        cap.release()


# ===============================
#   ç„¡éŸ³æ¤œå‡ºã‚¹ãƒ¬ãƒƒãƒ‰
# ===============================
class SilenceDetectionThread(threading.Thread):
    """ç„¡éŸ³æ™‚ã«å¹ãå‡ºã—ã‚’éè¡¨ç¤ºã«ã™ã‚‹ã‚¹ãƒ¬ãƒƒãƒ‰"""
    def __init__(self):
        super().__init__()
        self.running = True
        self.daemon = True

    def run(self):
        while self.running:
            time.sleep(0.5)

            # æœ€å¾Œã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰ä¸€å®šæ™‚é–“çµŒéã—ãŸã‚‰éè¡¨ç¤º
            if system_state.is_visible:
                elapsed = time.time() - system_state.last_transcript_time
                if elapsed >= SILENCE_THRESHOLD:
                    system_state.is_visible = False
                    socketio.emit('hide_bubble')
                    logger.info("Hiding bubble due to silence")


# ===============================
#   ãƒ­ãƒ¼ã‚«ãƒ«IPã‚¢ãƒ‰ãƒ¬ã‚¹å–å¾—
# ===============================
def get_local_ip():
    """ãƒ­ãƒ¼ã‚«ãƒ«IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’å–å¾—"""
    try:
        # ãƒ€ãƒŸãƒ¼æ¥ç¶šã§ãƒ­ãƒ¼ã‚«ãƒ«IPã‚’å–å¾—
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        local_ip = s.getsockname()[0]
        s.close()
        return local_ip
    except Exception:
        return "127.0.0.1"


# ===============================
#   ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# ===============================
def main():
    global TRANSCRIPT_LANGUAGE_CODE, TARGET_LANGUAGE_CODE

    # è¨€èªè¨­å®š
    source_lang, target_lang = get_language_settings()
    TRANSCRIPT_LANGUAGE_CODE = source_lang
    TARGET_LANGUAGE_CODE = target_lang
    logger.info(f"Selected source language: {source_lang}, target language: {target_lang}")

    # å„ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’èµ·å‹•
    logger.info("Starting audio transcription thread...")
    audio_thread = AudioTranscriptionThread()
    audio_thread.start()

    logger.info("Starting face detection thread...")
    face_thread = FaceDetectionThread()
    face_thread.start()

    logger.info("Starting silence detection thread...")
    silence_thread = SilenceDetectionThread()
    silence_thread.start()

    # ãƒ­ãƒ¼ã‚«ãƒ«IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’è¡¨ç¤º
    local_ip = get_local_ip()
    print("\n" + "="*60)
    print("ğŸ‰ Server is running!")
    print("="*60)
    print(f"\nğŸ“± iPhoneã®ãƒ–ãƒ©ã‚¦ã‚¶ã§ä»¥ä¸‹ã®URLã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ãã ã•ã„:")
    print(f"\n   http://{local_ip}:5010")
    print(f"\n   (ã¾ãŸã¯ http://localhost:5010 ã§ãƒ­ãƒ¼ã‚«ãƒ«ç¢ºèª)")
    print("\n" + "="*60 + "\n")

    # Flaskã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œï¼‰
    socketio.run(app, host='0.0.0.0', port=5010, debug=False, use_reloader=False)


if __name__ == "__main__":
    main()
